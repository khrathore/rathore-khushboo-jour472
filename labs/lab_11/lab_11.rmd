---
title: "lab_11"
author: "Khushboo Rathore"
date: "2023-04-27"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## You will need

* Our usual libraries for working with data, plus rvest.

## Load libraries and establish settings

**Task** Create a codeblock and load appropriate packages and settings for this lab.

```{r}
library(tidyverse)
library(janitor)
library(rvest)
library(lubridate)
library(ggplot2)
library(tidycensus)
```

Let's get to scraping.

## Questions

**Q1**. Scrape the listing of available Maryland state grants at https://grants.maryland.gov/Pages/StateGrants.aspx into a dataframe. You should have three columns, one of which is a date, so make sure the date column has a date datatype. Then, write code to count the number of grants opportunities offered by each organization listed in your dataframe, showing the organization with the most grant opportunities first. Which state agency has the most?

**A1** 

I tried to standardize the results as much as I could, and I landed on the Maryland Energy Administration. However, it's worth noting that some of the organizations worked together for grants, and that the naming may not be consistent. For instance, the "Transportation" organization could combine with MDOT and the MVA, but even looking at the website doesn't give much clarity on this topic. Some of these organizations may also be inside of each other (like the governor's volunteer and crime organizations could all fit under the Governor). 

```{r}
grants_url <- "https://grants.maryland.gov/Pages/StateGrants.aspx"

table_list <- grants_url %>% 
  read_html() %>% 
  html_table()

grant_table <- table_list[[1]] %>% 
  clean_names() %>% 
  mutate(due_date = mdy(due_date))

grants_by_org <- grant_table %>%
  mutate(organization = case_when(
    str_detect(organization, "Energy")~"Maryland Energy Administration",
    str_detect(organization, "Arts")~"Maryland State Arts Council",
    str_detect(organization, "Commerce")~"Maryland Department of Commerce",
    str_detect(organization, "Higher")~"Maryland Higher Education Commission",
    TRUE~organization
  )) %>% 
  group_by(organization) %>% 
  summarize(
    num_grants = n()
  ) %>% 
  arrange(desc(num_grants))

```

**Q2** Next, let's scrape the list of press releases from Maryland's Office of the Public Defender, https://www.opd.state.md.us/press-releases. This isn't a table, so you'll need to use `html_elements()` and your browser's inspector and do some clean up on the results. The result should be a dataframe with two columns that contain the date and title, and the date column should have a date datatype. The challenge here is figuring out how to isolate the releases.

When you finish scraping into a dataframe, write code to find the press releases that have the word "police" in the title. How many are there and when was the most recent one?

**A2** 
There are 9 of these press releases, the most recent being on June 6, 2021.
```{r}
press_url <- "https://www.opd.state.md.us/press-releases"

list_table <- press_url %>% 
  read_html() %>%
  ## Found this solution with help of https://cran.r-project.org/web/packages/rvest/vignettes/rvest.html
  html_elements('p a.wixui-rich-text__text') %>%
  html_text() %>% 
  as.tibble()

clean_press_release <- list_table %>% 
  separate(value, c('date', 'title'), sep=":") %>% 
  mutate(title = case_when(
    is.na(title)~str_squish(date),
    TRUE~str_squish(title)
  )) %>% 
  mutate(date = mdy(date))

police_releases <- clean_press_release %>% 
  filter(str_detect(title, "(p|P)olice"))

```

**Q3** Sen. Ben Cardin, D-Maryland, has posted hundreds of press releases at https://www.cardin.senate.gov/?post_type=press-releases. It would be great to have all of them in a dataframe that has the following columns: date, title and url.

To do this, you will need to scrape the page's html and save that to a variable, and _then_ extract the dates, titles and urls into _separate_ dataframes using html_elements(). And remember how we turn a list into a dataframe. The function `html_text()` pulls out the contents of a tag, but for urls we want the HTML attribute. Rvest gives you a way to extract the URL from a link; google to find out what it is.

At the end, you'll have three dataframes that you want to combine into a single dataframe. When we want to combine the rows of identical dataframes, we used `bind_rows()`. If you were combining columns instead of rows, there's a similar function. Find out what it is and use it to put all of the dataframes together into a single one.

When you're done, rename the columns so they make sense, then make sure the date column is an actual date.

Finally, tell me what questions you could ask of this data. Be creative.

**A3** 
In how many of these press releases does Cardin reference work he's done with other politicians? Further, which politicians does he partner with most often (including party, state, and tenure) and on what topics? Additionally, how often is there a mention of bipartisanship in his releases?

What topics does Cardin create press releases about most often and how does this compare to the platform he ran on for election? How much money has Cardin worked to give to various communities and organizations in the past few years? Where has most of the money gone and how does that compare to his platform?

As we get closer to 2024, or if we can get historical data, how do his press releases change closer to election season? Do they become more about his campaign or do they still talk about the work he is doing in the Senate? Does it also mellow out and become less political so that he can get Republicans to vote for him? Or does he stay truer to his Democrat roots? Do they relate more to things that support his platform or do they remain the way they currently are? Aka, do these press releases become a political campaign tool for Cardin during the election cycle?

Is there a pattern to his press releases? Are they more political closer to the end of the legislative session? What about during the budget season?

How many of his press releases contain information that directly impacts Marylanders? 
```{r}
cardin_url <- "https://www.cardin.senate.gov/?post_type=press-releases"
cardin_html <- cardin_url %>% 
  read_html()

cardin_dates <- cardin_html %>% 
  html_elements("h5") %>% 
  html_text() %>% 
  as.tibble() %>% 
  rename(date = value) %>% 
  mutate(date = mdy(date))

cardin_titles <- cardin_html %>% 
  html_elements("h3") %>% 
  html_text() %>% 
  as.tibble() %>%
  rename(title = value) %>% 
  mutate(title = str_squish(title))

cardin_url <- cardin_html %>% 
  html_elements("h3 a") %>% 
  # Found using https://rvest.tidyverse.org/reference/html_attr.html
  html_attr("href") %>% 
  as.tibble() %>%
  rename(url = value) %>% 
  mutate(url = str_squish(url))

cardin_press_releases <- cardin_dates %>% 
  # Found using https://dplyr.tidyverse.org/reference/bind.html
  bind_cols(cardin_titles, cardin_url)

```
